# CALLBACK'LER NEDÄ°R VE NE Ä°ÅE YARAR?

## ğŸ“š Genel BakÄ±ÅŸ

**Callback'ler**, model eÄŸitimi sÄ±rasÄ±nda belirli noktalarda otomatik olarak Ã§alÄ±ÅŸan fonksiyonlardÄ±r. Model eÄŸitimini optimize etmek, izlemek ve kontrol etmek iÃ§in kullanÄ±lÄ±rlar.

## ğŸ¯ Callback'lerin AmacÄ±

1. **EÄŸitimi Optimize Etmek**: Gereksiz epoch'larÄ± Ã¶nlemek, Ã¶ÄŸrenme oranÄ±nÄ± ayarlamak
2. **En Ä°yi Modeli Kaydetmek**: EÄŸitim sÄ±rasÄ±nda en iyi performans gÃ¶steren modeli otomatik kaydetmek
3. **Overfitting'i Ã–nlemek**: Modelin eÄŸitim verisine aÅŸÄ±rÄ± uyum saÄŸlamasÄ±nÄ± engellemek
4. **Zaman ve Kaynak Tasarrufu**: Gereksiz eÄŸitim sÃ¼resini Ã¶nlemek

---

## ğŸ” 1. EARLY STOPPING (Erken Durdurma)

### Ne Ä°ÅŸe Yarar?

Early Stopping, model eÄŸitimi sÄ±rasÄ±nda validasyon loss'u (kayÄ±p) iyileÅŸmediÄŸinde eÄŸitimi otomatik olarak durdurur.

### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

```python
EarlyStopping(
    monitor='val_loss',           # Ä°zlenecek metrik: validasyon loss
    patience=10,                  # 10 epoch boyunca iyileÅŸme olmazsa durdur
    restore_best_weights=True,    # En iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kle
    verbose=1                     # Bilgilendirme mesajlarÄ±nÄ± gÃ¶ster
)
```

### Ã–rnek Senaryo:

```
Epoch 1: val_loss = 0.5
Epoch 2: val_loss = 0.4  âœ“ Ä°yileÅŸti
Epoch 3: val_loss = 0.35  âœ“ Ä°yileÅŸti
Epoch 4: val_loss = 0.36  âœ— KÃ¶tÃ¼leÅŸti (patience baÅŸladÄ±)
Epoch 5: val_loss = 0.37  âœ— KÃ¶tÃ¼leÅŸti (patience: 1/10)
Epoch 6: val_loss = 0.38  âœ— KÃ¶tÃ¼leÅŸti (patience: 2/10)
...
Epoch 15: val_loss = 0.45  âœ— KÃ¶tÃ¼leÅŸti (patience: 10/10)
â†’ EÄŸitim durduruldu! En iyi model (Epoch 3) geri yÃ¼klendi.
```

### Neden Ã–nemli?

- âœ… **Zaman Tasarrufu**: Gereksiz epoch'larÄ± Ã¶nler
- âœ… **Overfitting Ã–nleme**: Model aÅŸÄ±rÄ± Ã¶ÄŸrenmeye baÅŸladÄ±ÄŸÄ±nda durdurur
- âœ… **En Ä°yi Model**: Otomatik olarak en iyi performans gÃ¶steren modeli seÃ§er
- âœ… **Kaynak Tasarrufu**: CPU/GPU kullanÄ±mÄ±nÄ± optimize eder

### Parametreler:

- **monitor**: Ä°zlenecek metrik (`'val_loss'`, `'val_accuracy'`, `'loss'`, vb.)
- **patience**: KaÃ§ epoch bekleyecek (varsayÄ±lan: 10)
- **restore_best_weights**: En iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kle (True/False)
- **verbose**: Bilgilendirme mesajlarÄ± (0=sessiz, 1=mesajlar)

---

## ğŸ“‰ 2. REDUCE LR ON PLATEAU (Ã–ÄŸrenme OranÄ± Azaltma)

### Ne Ä°ÅŸe Yarar?

Validasyon loss'u belirli bir sÃ¼re iyileÅŸmediÄŸinde, Ã¶ÄŸrenme oranÄ±nÄ± (learning rate) otomatik olarak azaltÄ±r.

### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

```python
ReduceLROnPlateau(
    monitor='val_loss',        # Ä°zlenecek metrik
    factor=0.5,                # Ã–ÄŸrenme oranÄ±nÄ± yarÄ±ya indir
    patience=5,                # 5 epoch bekleyip iyileÅŸme yoksa azalt
    min_lr=0.00001,           # Minimum Ã¶ÄŸrenme oranÄ± (daha fazla azaltma)
    verbose=1                  # Bilgilendirme mesajlarÄ±
)
```

### Ã–rnek Senaryo:

```
BaÅŸlangÄ±Ã§ Learning Rate: 0.001

Epoch 1: val_loss = 0.5, LR = 0.001
Epoch 2: val_loss = 0.4, LR = 0.001  âœ“ Ä°yileÅŸti
Epoch 3: val_loss = 0.35, LR = 0.001 âœ“ Ä°yileÅŸti
Epoch 4: val_loss = 0.36, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience baÅŸladÄ±)
Epoch 5: val_loss = 0.37, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience: 1/5)
Epoch 6: val_loss = 0.38, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience: 2/5)
Epoch 7: val_loss = 0.39, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience: 3/5)
Epoch 8: val_loss = 0.40, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience: 4/5)
Epoch 9: val_loss = 0.41, LR = 0.001 âœ— KÃ¶tÃ¼leÅŸti (patience: 5/5)
â†’ Learning Rate azaltÄ±ldÄ±: 0.001 â†’ 0.0005

Epoch 10: val_loss = 0.35, LR = 0.0005 âœ“ Ä°yileÅŸti (yeni LR ile)
```

### Neden Ã–nemli?

- âœ… **Ä°nce Ayar**: Model yakÄ±nsamaya yaklaÅŸtÄ±ÄŸÄ±nda daha kÃ¼Ã§Ã¼k adÄ±mlarla ilerler
- âœ… **Daha Ä°yi SonuÃ§lar**: KÃ¼Ã§Ã¼k Ã¶ÄŸrenme oranÄ± ile daha hassas optimizasyon
- âœ… **Otomatik Optimizasyon**: Manuel mÃ¼dahale gerektirmez
- âœ… **Yerel Minimum'dan Ã‡Ä±kÄ±ÅŸ**: Bazen daha kÃ¼Ã§Ã¼k LR ile daha iyi sonuÃ§lar alÄ±nÄ±r

### Parametreler:

- **monitor**: Ä°zlenecek metrik (`'val_loss'`, `'val_accuracy'`, vb.)
- **factor**: Ã–ÄŸrenme oranÄ±nÄ± ne kadar azaltacak (0.5 = yarÄ±ya indir)
- **patience**: KaÃ§ epoch bekleyecek (varsayÄ±lan: 5)
- **min_lr**: Minimum Ã¶ÄŸrenme oranÄ± (daha fazla azaltma yapÄ±lmaz)
- **verbose**: Bilgilendirme mesajlarÄ±

### Ã–ÄŸrenme OranÄ± Nedir?

Ã–ÄŸrenme oranÄ± (Learning Rate), modelin her adÄ±mda ne kadar bÃ¼yÃ¼k deÄŸiÅŸiklik yapacaÄŸÄ±nÄ± belirler:
- **YÃ¼ksek LR (Ã¶rn: 0.01)**: BÃ¼yÃ¼k adÄ±mlar, hÄ±zlÄ± Ã¶ÄŸrenme ama kararsÄ±z
- **DÃ¼ÅŸÃ¼k LR (Ã¶rn: 0.0001)**: KÃ¼Ã§Ã¼k adÄ±mlar, yavaÅŸ ama stabil Ã¶ÄŸrenme
- **Adaptif LR**: Ä°htiyaca gÃ¶re otomatik ayarlanÄ±r (ReduceLROnPlateau)

---

## ğŸ’¾ 3. MODEL CHECKPOINT (Model Kaydetme)

### Ne Ä°ÅŸe Yarar?

EÄŸitim sÄ±rasÄ±nda belirli koÅŸullar saÄŸlandÄ±ÄŸÄ±nda (Ã¶rn: en iyi validasyon accuracy) modeli otomatik olarak kaydeder.

### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

```python
ModelCheckpoint(
    'best_model.h5',          # KayÄ±t dosya yolu
    monitor='val_accuracy',    # Ä°zlenecek metrik: validasyon accuracy
    save_best_only=True,      # Sadece en iyi modeli kaydet
    verbose=1                 # Bilgilendirme mesajlarÄ±
)
```

### Ã–rnek Senaryo:

```
Epoch 1: val_accuracy = 0.85 â†’ Model kaydedildi! (en iyi ÅŸimdilik)
Epoch 2: val_accuracy = 0.87 â†’ Model kaydedildi! (daha iyi)
Epoch 3: val_accuracy = 0.89 â†’ Model kaydedildi! (daha iyi)
Epoch 4: val_accuracy = 0.88 â†’ Model kaydedilmedi (daha kÃ¶tÃ¼)
Epoch 5: val_accuracy = 0.90 â†’ Model kaydedildi! (en iyi)
...
Epoch 50: val_accuracy = 0.88 â†’ Model kaydedilmedi
â†’ En iyi model (Epoch 5, accuracy=0.90) kaydedildi: best_model.h5
```

### Neden Ã–nemli?

- âœ… **En Ä°yi Modeli Koruma**: EÄŸitim sÄ±rasÄ±nda en iyi performansÄ± gÃ¶steren modeli kaydeder
- âœ… **GÃ¼venlik**: EÄŸitim kesilirse en iyi model zaten kaydedilmiÅŸ olur
- âœ… **Otomatik KayÄ±t**: Manuel mÃ¼dahale gerektirmez
- âœ… **Model KarÅŸÄ±laÅŸtÄ±rma**: FarklÄ± epoch'lardaki modelleri karÅŸÄ±laÅŸtÄ±rabilirsiniz

### Parametreler:

- **filepath**: Modelin kaydedileceÄŸi dosya yolu
- **monitor**: Ä°zlenecek metrik (`'val_accuracy'`, `'val_loss'`, vb.)
- **save_best_only**: Sadece en iyi modeli kaydet (True/False)
- **save_weights_only**: Sadece aÄŸÄ±rlÄ±klarÄ± kaydet (True/False)
- **verbose**: Bilgilendirme mesajlarÄ±

### Model Kaydetme SeÃ§enekleri:

```python
# Sadece en iyi modeli kaydet (Ã¶nerilen)
ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)

# Her epoch'ta kaydet (disk alanÄ± kullanÄ±r)
ModelCheckpoint('model_epoch_{epoch}.h5', save_freq='epoch')

# Sadece aÄŸÄ±rlÄ±klarÄ± kaydet (daha kÃ¼Ã§Ã¼k dosya)
ModelCheckpoint('weights.h5', save_weights_only=True)
```

---

## ğŸ”„ Callback'lerin Birlikte Ã‡alÄ±ÅŸmasÄ±

Bu Ã¼Ã§ callback birlikte Ã§alÄ±ÅŸarak model eÄŸitimini optimize eder:

```
Epoch 1-5:   Model eÄŸitiliyor...
             â†’ ModelCheckpoint: En iyi model kaydediliyor
             
Epoch 6-10:  Validasyon loss iyileÅŸmiyor...
             â†’ ReduceLROnPlateau: LR azaltÄ±ldÄ± (0.001 â†’ 0.0005)
             â†’ ModelCheckpoint: Yeni en iyi model kaydediliyor
             
Epoch 11-20: Hala iyileÅŸme yok...
             â†’ Early Stopping: Patience doldu (10/10)
             â†’ EÄŸitim durduruldu!
             â†’ En iyi model (Epoch 5) geri yÃ¼klendi
             â†’ best_model.h5 dosyasÄ± hazÄ±r
```

---

## ğŸ“Š GÃ¶rsel Ã–rnek

```
Epoch    | val_loss | val_acc | LR      | Action
---------|----------|---------|---------|------------------
1        | 0.50     | 0.85    | 0.001   | âœ“ Model kaydedildi
2        | 0.40     | 0.87    | 0.001   | âœ“ Model kaydedildi
3        | 0.35     | 0.89    | 0.001   | âœ“ Model kaydedildi
4        | 0.36     | 0.88    | 0.001   | âœ— (patience baÅŸladÄ±)
5        | 0.37     | 0.87    | 0.001   | âœ— (patience: 1/5)
6        | 0.38     | 0.86    | 0.001   | âœ— (patience: 2/5)
7        | 0.39     | 0.85    | 0.001   | âœ— (patience: 3/5)
8        | 0.40     | 0.84    | 0.001   | âœ— (patience: 4/5)
9        | 0.41     | 0.83    | 0.0005  | â†’ LR azaltÄ±ldÄ±!
10       | 0.35     | 0.89    | 0.0005  | âœ“ Model kaydedildi
11       | 0.36     | 0.88    | 0.0005  | âœ— (patience: 1/10)
...
20       | 0.45     | 0.80    | 0.0005  | âœ— (patience: 10/10)
         |          |         |         | â†’ EÄŸitim durduruldu!
         |          |         |         | â†’ En iyi model (Epoch 10) yÃ¼klendi
```

---

## âš™ï¸ Parametre Ã–nerileri

### HÄ±zlÄ± Test Ä°Ã§in:
```python
patience = 3              # Daha hÄ±zlÄ± durdurma
reduce_lr_patience = 2    # Daha hÄ±zlÄ± LR azaltma
```

### Dikkatli EÄŸitim Ä°Ã§in:
```python
patience = 15             # Daha uzun bekleme
reduce_lr_patience = 7    # Daha uzun LR bekleme
```

### YÃ¼ksek Performans Ä°Ã§in:
```python
patience = 10             # Dengeli
reduce_lr_patience = 5    # Dengeli
factor = 0.5              # LR'yi yarÄ±ya indir
min_lr = 0.00001          # Ã‡ok kÃ¼Ã§Ã¼k minimum LR
```

---

## ğŸ’¡ Ä°puÃ§larÄ±

1. **Early Stopping Patience**: 
   - KÃ¼Ã§Ã¼k veri setleri iÃ§in: 5-10
   - BÃ¼yÃ¼k veri setleri iÃ§in: 10-20

2. **Reduce LR Patience**:
   - Early Stopping'den daha kÃ¼Ã§Ã¼k olmalÄ± (Ã¶rn: 5 vs 10)
   - BÃ¶ylece Ã¶nce LR azalÄ±r, sonra eÄŸitim durur

3. **Monitor Metrikleri**:
   - `val_loss`: Loss azalmasÄ±nÄ± izler (dÃ¼ÅŸÃ¼k = iyi)
   - `val_accuracy`: Accuracy artÄ±ÅŸÄ±nÄ± izler (yÃ¼ksek = iyi)
   - Hangi metrik kullanÄ±lmalÄ±? â†’ Genellikle `val_loss` daha gÃ¼venilir

4. **Model Checkpoint**:
   - Her zaman `save_best_only=True` kullanÄ±n (disk alanÄ± tasarrufu)
   - `monitor='val_accuracy'` veya `monitor='val_loss'` kullanÄ±n

---

## ğŸ¯ Ã–zet

| Callback | Ne Yapar? | Ne Zaman KullanÄ±lÄ±r? |
|----------|-----------|---------------------|
| **Early Stopping** | EÄŸitimi durdurur | Overfitting baÅŸladÄ±ÄŸÄ±nda |
| **Reduce LR** | Ã–ÄŸrenme oranÄ±nÄ± azaltÄ±r | Model yakÄ±nsamaya yaklaÅŸtÄ±ÄŸÄ±nda |
| **Model Checkpoint** | En iyi modeli kaydeder | Her zaman (gÃ¼venlik iÃ§in) |

---

## ğŸ“ SonuÃ§

Callback'ler, model eÄŸitimini **otomatik olarak optimize eden** araÃ§lardÄ±r. Manuel mÃ¼dahale gerektirmeden:
- âœ… En iyi modeli bulur ve kaydeder
- âœ… Overfitting'i Ã¶nler
- âœ… Ã–ÄŸrenme oranÄ±nÄ± optimize eder
- âœ… Zaman ve kaynak tasarrufu saÄŸlar

Bu yÃ¼zden her model eÄŸitiminde mutlaka kullanÄ±lmalÄ±dÄ±rlar! ğŸš€

